  \section{Chapter 6}
    \subsection{65ページ9行目}
      $c_1U_1 + c_2U_2 \sim c_1V_1 + c_2V_2$について。\\
      \begin{align*}
        &\{x \mid (c_1U_1 + c_2U_2)(x) \neq (c_1V_1 + c_2V_2)(x)\} \\
        \Leftrightarrow &\{x \mid (c_1U_1 + c_2U_2)(x) - (c_1V_1 + c_2V_2)(x) \neq 0\} =: A
      \end{align*}
      の測度が$0$であることを示せばよい。
      明らかに、
      \[
        c_1U_1 \sim c_1V_1, c_2U_2 \sim c_2V_2
      \]
      である。したがって、
      \begin{align*}
        A_1 := \{x \mid c_1U_1(x) \neq c_1V_1(x)\} \\
        A_2 := \{x \mid c_2U_2(x) \neq c_2V_2(x)\}
      \end{align*}
      の測度はそれぞれ$0$である
      \footnote{別に$A_1$などと名前を付けなくてもいいが(むしろ名前を付けない方がわかりやすい。)、紙面のスペースの都合上名前を付けている。}。
      このとき、次が成立。
      \[
        A \subset A_1 \cup A_2
      \]
      背理法で示す。上式の左辺から任意に$x$を取る。$x \notin A_1 \cup A_2$、つまり、
      \[
        x \in A_1^c \cap A_2^c
        \]
      と仮定する。このとき、$c_1U_1(x) = c_1V_1(x), c_2U_2(x) = c_2V_2(x)$であるから、
      \[
        (c_1U_1 + c_2U_2)(x) - (c_1V_1 + c_2V_2)(x) = 0\
      \]
      より、矛盾する。また、
      \begin{multline*}
        A = \{x \mid (c_1U_1 + c_2U_2)(x) - (c_1V_1 + c_2V_2)(x) < 0\} \\
        \cup \{x \mid (c_1U_1 + c_2U_2)(x) - (c_1V_1 + c_2V_2)(x) > 0\}
      \end{multline*}
      であるから、$A$は可測集合。したがって、測度の単調性より、$A$の測度は$0$。

    \subsection{65ページ10行目}
      $U_n \to U$より、
      $N \in \NN$が存在して、
      $n \ge N \Rightarrow ||U_n - U|| < \varepsilon \quad (\forall \varepsilon > 0)$
      である。
      $U_n \sim V_n, U \sim V$より、$||V_N - V|| < \varepsilon$が分かる。

    \subsection{67ページ10行目から12行目}
      \subsubsection{(ii) $\Rightarrow$ (i)について。}
        (逆向きは本の中で証明されています。)

        任意の$Z \in \mathcal{K}$を取ると、$||X - Z|| \ge ||X - Y|| + \alpha$となることを示すとよい。
        ここで、$\alpha > 0$である。
        しかし、$Z$として$Y + tZ \quad (t \in \RR)$とすればよい。
        これは$\mathcal{L}^p$の線形性のためである。
        なんとなれば、
        $Z = \frac{-Y+ W}{t} \quad (\forall W \in \mathcal{K})$とすればよい。
        $\langle X - Y, Z \rangle = \EE[(X - Y)Z] = 0$
        即ち、$\EE[XY] = \EE[YZ]$が成り立つことに注意して、
        $||X - Y - tZ||^2$を計算すると分かる\footnote{2乗しないと計算しにくい。}。

      \subsubsection{$||Y - Y^{\prime}|| = 0$について。}
        \begin{align*}
          \EE[(X - Y)(Y - Y^{\prime})] = 0\\
          \EE[(X - Y^{\prime})(Y - Y^{\prime})] = 0
        \end{align*}
        という式をそれぞれ期待値の中身を展開して引き算すると、
        \[
          \EE[(Y - Y^{\prime})^2] = 0
        \]
        という式が求められるから$Y = Y^{\prime}\quad (a.s.)$。

    \subsection{70ページ8,9行目}
      \subsubsection{$(\mathbf{P}(u))^q \leq \mathbf{P}(u^q)$について。}
        記号が見慣れなくてよくわからないが、
        $\mathbf{P}$は直前で確率測度であると示しているから、
        $\mathbf{P}(u)$とは$\mathbf{P}$による$u$の期待値である。
        凸関数$c(x) = x ^q$を考えると、この不等式はイェンゼンの不等式を
        用いるとすぐに従うことが分かる。
        そのためには、イェンゼンの不等式を用いるための条件を満たしているかを
        確認しよう。
        $u$の定義は$f(s) = 0$の部分で$u(s) = 0$なので、
        下記の計算には本当は$1_{\{f(s) > 0\}}$を書いておくべき。

      \subsubsection{$\mathbf{P}(u^q) < \infty$であること}
        Chapter 5で見たように、$f,h$を可測関数、$\mu$を測度とすれば、
        \[
          (hf)\mu = h(f\mu)
        \]
        が成立していた。これを用いる。また、$\frac{1}{p} + \frac{1}{q} = 1$にも注意しておく。
        \begin{align*}
          \mathbf{P}(u^q) &= \frac{h^q}{f^{q(p-1)}}\frac{f^p\mu}{\mu(f^p)}
          = \frac{h^q}{f^p}\frac{f^p\mu}{\mu(f^p)}
          = \frac{h^q}{f^p}f^p \frac{\mu}{\mu(f^p)} \\
          &= h^q \frac{\mu}{\mu(f^p)} = \frac{h^q}{\mu(f^p)}\mu
          =\frac{1}{\mu(f^p)}\int h^q d\mu < \infty
        \end{align*}

      \subsubsection{$\mathbf{P}(u) < \infty$について}
        ヤングの不等式を用いる。
        \[
          ab \leq \frac{a^p}{p} + \frac{b^q}{q}
        \]
        \begin{align*}
          \mathbf{P}(u)
          = \frac{h}{f^{p-1}}\frac{f^p\mu}{\mu(f^p)}
          &= hf\frac{\mu}{\mu(f^p)}
          = \frac{hf}{\mu(f^p)}\mu \\
          &\leq \frac{1}{\mu(f^p)} \left( \frac{f^p}{p} + \frac{h^q}{q} \right) \mu
          < \infty
        \end{align*}

      \subsubsection{ヘルダーの不等式の証明}
        $(\mathbf{P}(u))^q \leq \mathbf{P}(u^q)$を展開する。
        ここでも$\frac{1}{p} + \frac{1}{q} = 1$を適宜変形して利用する。
        \begin{align*}
          \left( \frac{h}{\mu(f^{(p-1)}} 1_{\{f(s) > 0\}} \frac{f^p \mu}{\mu(f^p)} \right)^q
          &\leq
          \frac{h^q}{f^{q(p-1)}}1_{\{f(s) > 0\}}\frac{f^p}{\mu(f^p)} \\
          \left(\frac{1}{\mu(f^p)}\right)^q (hf\mu)^q
          &\leq
          \left(\frac{1}{\mu(f^p)}\right) \left(h^q\frac{f^p}{f^{q(p-1)}}1_{\{f(s) > 0\}}\mu \right)\\
          (hf\mu)^q
          &\leq
          (\mu(f^p))^{q-1} \left(h^q \frac{f^p}{f^p}1_{\{f(s) > 0\}} \mu\right)\\
          (hf\mu)^q
          &\leq
          (\mu(f^p))^{\frac{q}{p}}(h^q \mu) \\
          (hf\mu)
          &\leq
          (\mu(f^p))^{\frac{1}{p}}(h^q\mu)^{\frac{1}{q}} \\
          \int fh d\mu
          &\leq
          \left(\int f^p d\mu \right)^{\frac{1}{p}} \left(\int h^q d\mu \right)^{\frac{1}{q}}
        \end{align*}
        通常の$\log$を使う証明じゃないの面白いね。

  \section{Chapter 7}
    \subsection{大数の法則を証明する前の補題}
      \begin{prop*}
        $S_k$-値確率変数列$(X_k)_{k = 1,2,\cdots, n}$は独立で、
        $g_k \colon S_k \to S_k^{\prime}$
        は
        $\mathcal{S}_k$-可測関数とする。
        このとき、$Y_k = g_k(X_k)$とおけば、$(Y_k)_{k=1,2,\cdots,n}$は独立。
      \end{prop*}
      \begin{proof}
        $A_k^{\prime} \in \mathcal{S}_k^{\prime}$とする。
        \[
          \{Y_k \in A_k^{\prime}\} = \{X_k \in g_k^{-1}(A_k^{\prime})\}
        \]
        であり、$g_k$の可測性から、
        \[
          g_k^{-1}(A_k^{\prime}) \in \mathcal{S}_k
        \]
        であることから、
        \[
          \{X_k \in g_k^{-1}(A_k^{\prime})\} \in \sigma(X_k)
        \]
        よって、
        \begin{align*}
          \PP \left(\bigcap_{k=1}^{n} (Y_k \in A_k^{\prime})\right) &= \PP \left((\bigcap_{k=1}^{n} (X_k \in g_k^{-1}(A_k^{\prime}))\right) \\
          &= \prod_{k=1}^n \PP(X_k \in g_k^{-1}(A_k^{\prime}) \\
          &= \prod_{k=1}^n \PP(Y_k \in A_k^{\prime})
        \end{align*}
      \end{proof}

      \begin{prop*}
        $(X_k)_{k = 1,2,\cdots, n}$が$\RR$-値独立確率変数の列とする。
        $g = g(x_1, x_2, \cdots, x_i)$は$\RR^i \to \RR$のボレル可測関数とする。
        ただし、$i < n$。
        このとき、$Y := g(X_1, X_2, \cdots, X_i)$とおけば、
        $Y, X_{i+1}, \cdots, X_n$は独立。
      \end{prop*}
      \begin{proof}
        $X = (X_1, \cdots, X_i)$は$\RR^i$-値確率変数であり、
        $X, X_{i+1}, \cdots, X_{n}$
        は独立である。まずはこれを示す。
        $A \in \BB(\RR^i), A_{i+1}, \cdots, A_n \in \BB(\RR)$について、
        \begin{equation}\label{2-1}
          \PP(X \in A, X_{i+1} \in A_{i+1}, \cdots, X_n \in A_n) = \PP(X \in A)\prod_{j = i+1}^n \PP(X_j \in A_j)
        \end{equation}
        が成立することを言えばよい。そこで、
        \[
          \mathcal{L} = \{A \subset \RR^i \mid \text{(\ref{2-1})が成立}\}
        \]
        と定義する。$\mathcal{L}$は$\lambda$-systemである。
        明らかに$\Omega \in \mathcal{L}$である。
        次に、$A,B \in \mathcal{L}, A \subset B$とすると、
        $\PP(X \in B-A) = \PP(X \in B) - \PP(X \in A)$であることに注意すれば、
        \begin{align*}
          &\PP(X \in B-A, X_{i+1} \in A_{i+1}, \cdots, X_n \in A_n) \\
          =& \PP(X \in B, X_{i+1} \in A_{i+1}, \cdots, X_n \in A_n) - \PP(X \in A, X_{i+1} \in A_{i+1}, \cdots, X_n \in A_n) \\
          =& \PP(X \in B)\prod_{j = i+1}^n \PP(X_j \in A_j) - \PP(X \in A)\prod_{j = i+1}^n \PP(X_j \in A_j) \\
          =& \left( \PP(X \in B) - \PP(X \in A) \right)\prod_{j = i+1}^n \PP(X_j \in A_j) \\
          =& \PP(X \in B - A) \prod_{j = i+1}^n \PP(X_j \in A_j)
        \end{align*}
        なので、$B - A \in \mathcal{L}$。
        最後に、$A_n \in \mathcal{L} \quad (n = 1, 2, \cdots)$で、$A_n \uparrow A$とする。
        $X \in A$とすれば、$\exists m \in \NN \quad s.t. \quad X \in A_m$なので、
        そのような自然数で最小のものを$m$とする\footnote{自然数全体の部分集合は必ず最小限を持つ}。
        集合列$(A_n)$は包含関係に関して単調増加であるため、すべての$N \ge m$に対して、
        \[
          \{X \in A_m\} = \{X \in A_N\}
        \]
        が成立する。したがって当然
        \[
          \{X \in A_m\} = \bigcup_{k=N}^{\infty}\{X \in A_k\} = \{X \in A\}
        \]
        よって、
        \[
          \PP(X \in A_m) = \PP(X \in A)
        \]
        よって次のように計算ができる。
        \begin{align*}
          &\PP(X \in A, X_{i+1} \in A_{i+1}, \cdots, X_n \in A_n) \\
          =&\PP(X \in A_m, X_{i+1} \in A_{i+1}, \cdots, X_n \in A_n) \\
          =&\PP(X \in A_m)\prod_{j = i+1}^n \PP(X_j \in A_j) \\
          =&\PP(X \in A)\prod_{j = i+1}^n \PP(X_j \in A_j)
        \end{align*}
        これにより、$A \in \mathcal{L}$であることが分かる。
        以上より$\mathcal{L}$は$\lambda$-system。

        さて、
        $\mathcal{P} = \{A_1 \times \cdots \times A_i \mid A_k \in \BB(\RR) , k = 1, 2, \cdots, i\}$
        は$\pi$-systemであり、$A \in \mathcal{P}$とすれば、直積の定義より
        \[
          X \in A \Leftrightarrow X_1 \in A_1, \cdots, X_i \in A_i
        \]
        より、
        \[
          \{X \in A\} = \{X_1 \in A_1\} \cap \cdots \cap \{X_i \in A_i\}
        \]
        仮定から$X_1 ,\cdots , X_n$は独立なので
        \begin{align*}
            &\PP(X \in A ,X_{i+1} \in A_{i+1}, \cdots, X_n \in A_n) \\
            =& \prod_{k=1}^n\PP(X_k) \\
            =& \PP(X_1 \in A_1, \cdots, X_i \in A_i)\prod_{k=i+1}^n\PP(X_k \in A_k) \\
            =& \PP(X \in A)\prod_{k=i+1}^n\PP(X_k)
        \end{align*}
        と計算できるから、$A \in \mathcal{L}$がわかる。
        したがって$\mathcal{P} \subset \mathcal{L}$である。
        よって、$\pi$-$\lambda$定理より、
        \[
          \mathcal{L} \supset \sigma(\mathcal{P}) = \BB(\RR^i)
        \]
        以上により、$X, X_{i+1}, \cdots, X_n$は独立であることが分かった。

        あとは先の命題を適用すればよい。
      \end{proof}

      \begin{lem*}
        $X,Y,Z,W$は独立なr.v.とする。
        このとき、$(X,Y^n),(XY^2,Z),(XY,ZW),(X^2,Y^2)$はそれぞれ独立。
      \end{lem*}
      \begin{proof}
        確率変数の独立性は合成によって保たれることに注意する。

        $(X,Y^n)$に関しては、
        \begin{align*}
          f &\colon x \mapsto x \\
          g &\colon x \mapsto x^n
        \end{align*}
        として、$X = f(X), Y^n = g(Y)$と見る。

        $(XY^2,Z)$に関しては、
        \begin{align*}
          f &\colon (x, y) \mapsto xy^2 \\
          g &\colon x \mapsto x
        \end{align*}
        として、$XY^2 = f(X,Y), Z = g(Z)$として見る。

        $(XY,ZW)$に関しては、
        \begin{align*}
          f \colon (x, y) \mapsto xy
        \end{align*}
        として$XY = f(X,Y)$とみれば、$XY,Z,W$は独立。
        もう一度$ZW = f(Z,W)$とみれば、$XY,ZW$は独立。

        $(X^2,Y^2)$に関しては、
        \begin{align*}
          f \colon x \mapsto x^2
        \end{align*}
        として$X^2 = f(X), Y^2 = f(Y)$として見る。
      \end{proof}

    \subsection{73ページ下から3行目}
      まあ明らかなんだけど、さすがにそのまま引き算して証明できるほど明らかではない。

      $1_{\{|X - \mu| > c\}}$を考えよう。
      \[
        \PP(|X - \mu| > c) = \EE[1_{\{|X - \mu| > c\}}]
      \]
      であり、
      \[
        1_{\{|X - \mu| > c\}} < \frac{(X - \mu)^2}{c^2}
      \]
      が成立することに注意すると、両辺を積分して、
      \begin{align*}
        \int 1_{\{|X - \mu| > c\}} d\PP &\leq \int \frac{(X - \mu)^2}{c^2} d\PP \\
        \PP(|X - \mu| > c) & \leq \frac{1}{c^2}\EE[(X - \mu)^2] \\
        c^2 \PP(|X - \mu| > c) & \leq \EE[(X - \mu)^2] = \Var(X)\
      \end{align*}

    \subsection{74ページ(a)の2行上}
      $f$が有界なのは$f$が閉区間上の連続関数だから。
      位相空間でよくあるお話だけどただ単に「$f$は有界である」と書かれるのはちょっと...。

  \section{Chapter 8}
    眠いし疲れたので明日。
    なんか書かなきゃいけないことあったはずなんだけど、
    ちょっと忘れたよ。

  \section{Chapter 9}
    \subsection{$\EE[X;G]$という書き方について}
      Chapter 5で実は定義されています。
      \[
        \EE[X;G] := \int X 1_G d\PP = \int_G X d\PP
      \]

    \subsection{条件付き期待値の別の書き方について}
      積分の形での定義を、指示関数(定義関数)を使って書き換えたものが次の書き方。
      \begin{defn}
        $Y$が$X$の$\mathcal{G}$での条件付き期待値であるとは、
        任意の$G \in \mathcal{G}$に対して次が成立すること。
        \[
          \EE[X1_G ] = \EE[Y1_G]
        \]
        が成り立つこと。
      \end{defn}
      これは次のように書き換えられる。
      \begin{defn}
        $Y$が$X$の$\mathcal{G}$での条件付き期待値であるとは、
        任意の上に有界な非負の$\mathcal{G}$-可測関数$Z$に対して次が成立すること。
        \[
          \EE[XZ] = \EE[YZ]
        \]
        が成り立つこと。
      \end{defn}

      後者の定義から前者の定義が導かれるのは自明。
      前者の定義から後者の定義を導く。
      $(Z_n)$は$Z$に各点収束する単調増加な単関数の列とする。
      単関数は指示関数の有限個の和で表すことができるから、
      \[
        \EE[XZ_n] = \EE[YZ_n]
      \]
      が成り立つ。したがって、
      \[
        \lim_{n \to \infty} \EE[XZ_n] = \lim_{n \to \infty} \EE[YZ_n]
      \]
      が成り立つ。単調収束定理より、
      \begin{align*}
        \EE[\lim_{n \to \infty} XZ_n] &= \EE[\lim_{n \to \infty} YZ_n] \\
        \EE[XZ] &= \EE[YZ]
      \end{align*}
      がなりたつ。
      ($XZ_n,YZ_n$がそれぞれ単調増加な可測関数列である。)

    \subsection{86ページ3行目}
      \[
        \{ Y > \tilde{Y} + \frac{1}{n} \} \uparrow
        \{ Y > \tilde{Y}\}
      \]
      とは、
      \[
        \bigcup_{n}\{ Y > \tilde{Y} + \frac{1}{n} \} =
        \{ Y > \tilde{Y}\}
      \]
      よって、
      \[
        \sum_n \PP(Y > \tilde{Y} + \frac{1}{n})
        \ge
        \PP \left(\bigcup_{n}\{ Y > \tilde{Y} + \frac{1}{n} \} \right)
        \ge
        \PP(Y > \tilde{Y})
        > 0
      \]
      であることに注意する。

      \subsection{86ページ下から6行目}
        \underline{almost surely}で$Y_n$が非負かつ、$n$に関して単調増加であることを示すことに気を付ける。
      \subsubsection{$0 \leq Y_n$(a.s.) について}
        $F := \{ Y_n < 0 \}$について考える。
        $Y_n$は$\mathcal{G}$可測なので、
        $F$は$\mathcal{G}$可測集合となる。
        $Y_n$が$X_n$の条件付き期待値であることと、
        非負の可測関数を確立測度で積分するとその値は非負になることに気をつければ、以下のように計算することができる。
        \begin{equation*}
          \int_F Y_n d\PP = \int_F X_n d\PP \ge 0
        \end{equation*}
        一方、
        \[
          \int_F Y_n d\PP = \int_{\Omega} Y_n 1_F d\PP
        \]
        だから、
        \[
          \int_{\Omega} Y_n 1_F d\PP \ge 0
        \]
        となる。
        さて、
        \[
          Y_n 1_F(\omega) \leq 0 \quad (\forall \omega \in \Omega)
        \]
        だから、
        \[
          \int_{\Omega} Y_n 1_F d\PP \leq 0
        \]
        よって、
        \[
          \int_{\Omega} Y_n 1_F d\PP = 0
        \]
        これから、
        \[
          \int_{\Omega} -Y_n 1_F d\PP = 0
        \]
        51ページのLemma(b)を用いると
        \[
          \PP(F) = 0
        \]
        が分かる。

      \subsubsection{$Y_n \uparrow$(a.s.)について}
        前小小節とほぼ同じ。
        $s < r$として、$G := \{ Y_s > Y_r \}$
        上で$X_s,X_r$をそれぞれ積分する。
        そしてそれらを引き算する。

    \subsection{86ページ下から3行目$Y_n \uparrow Y$(a.s)について}
      上極限の扱い分かってない人みたいになった。

      各点収束することを示すから、$\omega \in \Omega$を一つ固定する。
      \subsubsection{$\limsup_{n \to \infty}{Y_n(\omega)} = \infty$のとき}
        \[
          \limsup_{n \to \infty}{Y_n(\omega)} = \inf_{n \ge 1} \sup_{\nu \ge n} Y_{\nu}(\omega)
        \]
        である(定義)。見やすさのために、新たに
        \[
          a_n = \sup_{\nu \ge n} Y_{\nu}(\omega)
        \]
        とおく。すると、
        \[
          \inf_{n \ge 1} a_n
        \]
        となる。
        探索範囲が狭まっているので$a_n$は単調減少列であることに注意する。
        仮定より、
        \[
          \inf_{n \ge 1} a_n = \infty
        \]
        だから、
        \[
          a_n = \infty \quad (\forall n)
        \]
        つまり、とりわけ$n=1$に関して
        \[
          \sup_{\nu \ge 1} Y_{\nu}(\omega) = \infty
        \]
        これはつぎのように書ける。
        \[
          \forall K >0 , \exists m \in \NN \quad s.t. \quad Y_m(\omega) > K
        \]
        これは、数列$(Y_n(\omega))$が正の無限大に発散することの定義そのものである。
        したがって、
        \[
          \lim_{n \to \infty} Y_n(\omega) = \infty
        \]

      \subsubsection{$\limsup_{n \to \infty}{Y_n(\omega)} = \alpha < \infty$のとき}
        定義より、
        \[
          \limsup_{n \to \infty}{Y_n(\omega)} = \inf_{n \ge 1} \sup_{\nu \ge n} Y_{\nu}(\omega)
        \]
        であるが、$Y_{n}(\omega)$は$n$に関する単調増加列なので、
        各$b_n$の値は全て等しい。ただし、
        \[
          b_n = \sup_{\nu \ge n} Y_{\nu}(\omega)
        \]
        したがって、
        \[
          \inf_{n \ge 1} \sup_{\nu \ge n} Y_{\nu}(\omega) = \sup_{n \ge 1}Y_n(\omega)
        \]
        つまり、
        \[
          \sup_{n \ge 1}Y_n(\omega) = \alpha
        \]
        であることが分かる。
        よって、$Y_n(\omega)$は上限が$\alpha$の単調増加な数列なので
        \[
          \lim_{n \to \infty}Y_n(\omega) = \alpha
        \]

    \subsection{89ページ(d)の証明について}
      (9.5.d)の証明を用いればよいと書いてあるが、
      (9.5.d)の主張を証明するために有界性は用いていない。
      したがって、(9.5.d)証明がそのまま(d)の証明になる。

    \subsection{89ページ(f),(g)の証明について}
      いくつかの補題を先に証明する。
      \subsubsection{補題その1}
        \begin{lem}\label{lem1}
          $X,Y$: 確率変数で、$X \leq Y \quad (a.s)$とする。
          このとき、$\EE[X \mid \mathcal{G}] \leq \EE[Y \mid \mathcal{G}] \quad (a.s.)$
        \end{lem}

        \begin{proof}
          仮定より、$0 \leq Y - X$だから、88ページ(d)より、
          \[
            0 \leq \EE[ Y - X \mid \mathcal{G}]
          \]
          88ページ(c)の線形性から、
          \[
            \EE[X \mid \mathcal{G}] \leq \EE[Y \mid \mathcal{G}]
          \]
        \end{proof}

      \subsubsection{補題その2}
        \begin{lem}[Reverse cFATOU]\label{lem2}
          $|X_n(\omega)| \leq V(\omega) \, (\forall n), \quad \EE[V] < \infty$
          であるなら、
          \[
            \EE[\limsup_{n \to \infty}X_n | \mathcal{G}] \ge \limsup_{n \to \infty}\EE[X_n | \mathcal{G}]
          \]
        \end{lem}

        \begin{proof}
          $(V - X_n)$にcFATOUを適用する。
          \begin{align*}
            \EE[\liminf_{n \to \infty}(V - X_n) \mid \mathcal{G}] &\leq \liminf_{n \to \infty}\EE[V - X_n \mid \mathcal{G}] \\
            \\
            \EE[V + \liminf_{n \to \infty}(- X_n) \mid \mathcal{G}]
            &\leq
             \liminf_{n \to \infty}(\EE[V \mid \mathcal{G}] + \EE[- X_n \mid \mathcal{G}]) \\
             \\
             \EE[\liminf_{n \to \infty}(- X_n) \mid \mathcal{G}]
             &\leq
             \liminf_{n \to \infty} \EE[- X_n \mid \mathcal{G}]\\
             \\
             \EE[- \liminf_{n \to \infty}(- X_n) \mid \mathcal{G}]
             &\ge
             -\liminf_{n \to \infty} \EE[- X_n \mid \mathcal{G}]\\
             \\
             \EE[\limsup_{n \to \infty}X_n | \mathcal{G}]
             &\ge
             \limsup_{n \to \infty}\EE[X_n | \mathcal{G}]\\
          \end{align*}
        \end{proof}

      \subsubsection{補題その3}
        \begin{lem}\label{lem3}
          $|\EE[X \mid \mathcal{G}]| \leq \EE[|X| \mid \mathcal{G}]$
        \end{lem}
        \begin{proof}
          \[
            -\EE[|X| \mid \mathcal{G}] \leq \EE[X \mid \mathcal{G}] \leq \EE[|X| \mid \mathcal{G}]
          \]
          を示せばよい。

          右側の不等式は$X \leq |X|$よりわかる。
          左側の不等式は$-|X| \leq X$よりわかる。
        \end{proof}

      \subsubsection{(f)の証明}
        $k \in \NN$とする。
        $n \ge k$において、$\inf_{n \ge k}X_n \leq X$が成立する。
        補題\ref{lem1}より、
        \[
          \EE[\inf_{n \ge k}X_n \mid \mathcal{G}] \leq \EE[X \mid \mathcal{G}]
        \]
        $n \ge k$について下限をとると、
        \[
          \EE[\inf_{n \ge k}X_n \mid \mathcal{G}] \leq \inf_{n \ge k} \EE[X \mid \mathcal{G}]
        \]
        $k \to \infty$とすると、(cMON)と$\inf_{n \ge k}X_n$は$k$に関する単調増加列であることから、
        主張の式が得られる。

      \subsubsection{(g)の証明}
        補題\ref{lem3}より、
        \[
          |\EE[X_n - X \mid \mathcal{G}]| \leq \EE[|X_n - X| \mid \mathcal{G}]
        \]
        だから、
        \begin{align*}
          \lim_{n \to \infty}|\EE[X_n - X \mid \mathcal{G}]|
          &\leq
          \lim_{n \to \infty}\EE[|X_n - X| \mid \mathcal{G}]\\
          \\
          &\leq \limsup_{n \to \infty}\EE[|X_n - X| \mid \mathcal{G}]
        \end{align*}
        である。ここで補題\ref{lem2}より、
        \begin{align*}
          \limsup_{n \to \infty}\EE[|X_n - X| \mid \mathcal{G}]
          &\leq
          \EE[\limsup_{n \to \infty}|X_n - X| \mid \mathcal{G}]\\
          \\
          = \EE[0 \mid \mathcal{G}]\\
        \end{align*}
        したがって、
        \[
          \limsup_{n \to \infty}\EE[|X_n - X| \mid \mathcal{G}] = 0
        \]
        よって、はさみちの原理から、
        \[
          \lim_{n \to \infty}|\EE[X_n - X \mid \mathcal{G}]| = 0
        \]
        ゆえに、
        \[
          \lim_{n \to \infty}\EE[X_n \mid \mathcal{G}] = \EE[X \mid \mathcal{G}]
        \]

    \subsection{(j)について}
      (***)にある『適切な可積分条件』とは
      \[
        \EE[|ZX|] < \infty
      \]
      のこと。これがないとそもそも条件付き期待値が定義できない。
      本の証明は$\EE[|ZX|] < \infty$を仮定して、先に(***)の条件を証明している。
      そのご、各条件に付いて$\EE[|ZX|] < \infty$を満たしているかどうかをチェックしている。

      『適切な可積分条件』とかふわふわした書き方しないでよ、分からないでしょ！

    \subsection{(k)について}
      \subsubsection{証明1行目}
        $\EE[X] < \infty$は条件付き期待値を定義するために必要な条件だから書いてあります。
        9.7のリストの最初に$\EE[|X|] < \infty$を仮定すると書いてあるので、それはそう。

      \subsubsection{証明2行目}
        「$XI_G$ and $H$ are independent」は「$XI_G$ and $I_H$ are independent」
        のこと。

        また、この主張は
        $\sigma(XI_G) \subset \sigma(\sigma(X), \mathcal{G})$
        と
        $\sigma(I_H) \subset \sigma(\mathcal{H})$
        を示せばよい。
        これが示されれば、
        \[
          A \in \sigma(XI_G) \Rightarrow A \in \sigma(\sigma(X), \mathcal{G})
        \]
        \[
          B \in \sigma(I_H) \Rightarrow B \in \sigma(\mathcal{H})
        \]
        が分かるので、$\sigma(\sigma(X), \mathcal{G})$と$\sigma(\mathcal{H})$
        が独立であるという仮定を利用すればよい。

        $\sigma(XI_G) \subset \sigma(\sigma(X), \mathcal{G})$は、
        $X$は$\sigma(X)$上可測であり、$I_G$は$\mathcal{G}$上可測だから、
        それぞれ$\sigma(\sigma(X), \mathcal{G})$可測である。
        よって、$XI_G$は$\sigma(\sigma(X), \mathcal{G})$上で可測。
        したがって、$\sigma(XI_G) \subset \sigma(\sigma(X), \mathcal{G})$。もう一個もおんなじ感じやで。

      \subsubsection{4行目}
        $Y$は$\mathcal{G}$可測だから、$YI_G$も$\mathcal{G}$可測で、
        ゆえに、
        $\sigma(YI_G) \subset \mathcal{G} \subset \sigma(\sigma(X),\mathcal{G})$より、
        $\sigma(YI_G)$と$\sigma(I_H)$は独立。

      \subsubsection{10行目}
        この書き方嫌い。例えば次のように書けば見やすいのでは?

        二つの写像、$\mu_1, \mu_2$を次のように定義する。
        \[
        \mu_1 \colon \sigma(\mathcal{G},\mathcal{H}) \rightarrow \RR
        \]
        という写像で、$\mu_1(F) = \EE[X ; F]$とする。
        また、
        \[
        \mu_2 \colon \sigma(\mathcal{G},\mathcal{H}) \rightarrow \RR
        \]
        という写像で、$\mu_2(F) = \EE[Y ; F]$とする。

      \subsubsection{11行目}
        ここの書き方も嫌い。記号を使った方が分かりやすいと思う...

        \[
          \mathcal{I} := \{G \cap H \mid G \in \mathcal{G}, H \in \mathcal{H}\}
        \]
        とすると、$\mu_1 , \mu_2$が$\mathcal{I}$上で一致する。\\
        てな感じで書いてくれないと英語読めない人死亡する。

      \subsubsection{12行目}
        "... and hence agree everywhere on $\sigma(\mathcal{G},\mathcal{H})$"
        じゃねえんだよな。使った補題くらい明記しとけや。

        $\sigma(I) = \sigma(\mathcal{G},\mathcal{H})$より、
        19ページの補題から、$\mu_1 , \mu_2$は$\sigma(\mathcal{G},\mathcal{H})$
        で一致する。

        くらいはせめて言葉を尽くして欲しかった。

      \subsubsection{後半の主張}
        これ前半の主張の式使って証明できるの？

        $Y$を$\EE[X \mid \mathcal{H}]$の一変形とする。
        $H \in \mathcal{H}$を任意にとる。
        \begin{align*}
          \EE[Y;H] &= \EE[X;H] \\
          &= \EE[XI_H] \\
          &= \EE[X]\EE[I_H] \\
          &= \int_H \EE[X] d\PP \\
          &= \EE[\EE[X];H]
        \end{align*}
        より、$\EE[X \mid \mathcal{H}] = \EE[X]$が言える。
        なお、この計算の途中で$X,I_H$が独立であることを用いた。

    \subsection{9.9節について}
      \subsubsection{(a)の式の証明}
        これくらいの行間なら許せる。
        \begin{proof}
          \[
            G_n = \sum_{k = 1}^{n} I_{F_k}
          \]
          とする。
          $(F_n)$はdisjointな集合の列だから、
          $(G_n)$は単調増加な非負の関数列である。
          \begin{align*}
            \PP \left( \bigcup_{n = 1}^{\infty} F_n \mid \mathcal{G}\right) &= \EE[I_{\sum_n F_n \mid \mathcal{G}}]\\
            &= \EE[\lim_{n \to \infty}G_n \mid \mathcal{G}] \\
            &= \lim_{n \to \infty} \EE[G_n \mid \mathcal{G}] \\
            &= \lim_{n \to \infty} \sum_{k = 1}^n \EE[I_{F_k} \mid \mathcal{G}] \\
            &= \sum_{n = 1}^{\infty}\EE[I_n \mid \mathcal{G}]\\
            &= \sum_{n = 1}^{\infty}\PP (F_n \mid \mathcal{G})
          \end{align*}
          ただし、この計算の途中で(cMON)および(cDOM)を用いている。
        \end{proof}

      \subsubsection{$P(\cdot,\cdot)$の存在を(a)から言うことができないことについて}
        お前は許せないタイプの行間。

        すこし論理記号を用いて書くとするならば、以下のような感じになるだろう。\footnote{\LaTeX がなんかいい感じに書けなかった。}\footnote{ここで大切なのは$(F_n)$が$\PP$のカッコの中にないということ。}
        \[
          \forall (F_n):\text{disjoint} \quad [\PP \left( \bigcup_{n = 1}^{\infty} F_n \mid \mathcal{G}\right) = \sum_{n = 1}^{\infty}\PP (F_n \mid \mathcal{G}) \text{が} (a.s.)　\text{で成り立つ。}]
        \]
        すなわち、$(F_n)$を固定するごとに、上記の等式が成り立たないような零集合が存在する。
        確率空間$(\Omega, \mathcal{F}, \PP)$が簡単なものではない場合、
        つまり、$\mathcal{F}$が有限だったり、可算集合でない場合、
        $\mathcal{F}$上のdisjointな集合列は非可算個存在する。
        そこで、そのような零集合を$N_{(F_n)}$と書くことにする。
        \[
          N := \bigcup_{(F_n)} N_{(F_n)}
        \]
        と定める。
        $\mathcal{F}$内の$(F_n)$をすべて動かしたときの$N_{(F_n)}$の和集合である。
        $N$は(b2)が成り立たない集合である。
        しかし、これはそもそも可測ではないかもしれないし、
        可測であったとしても零集合の非可算個の和集合なので、
        その測度は$0$よりも大きくなりえる。
        だから、$P(\cdot,\cdot)$の存在を(a)から言うことができないのである。

        \subsubsection{正則条件付き確率が存在することの必要十分条件(?)について}
          D. L
          %\EE
          AO, M. FRAGOSO and P. RUFFINOらによる2003年の論文
          \footnote{https://scielo.conicyt.cl/pdf/proy/v23n1/art02.pdf}(最近だな！)
          にいろいろ情報が書かれてあった。
          (まだ読んでないですが)

    \subsection{9.10について}
      \subsubsection{91ページ(b)の式について}
          $\gamma^{h}(X_1)$は$X_1$を一つ決め打ちした時の$h$の期待値。
          $\EE[h(X_1,X_2, \cdots , X_r) \mid X_1]$は$\sigma(X_1)$という条件が付いたときの$h$の期待値。
          これらの二つが実は同じ\footnote{「同じ」と言ってしまうと語弊があるけど...}ですよ～って意味。

      \subsubsection{(c)が成り立てば証明できたことになる？}
          主張の式を確認するためには、任意の$G \in \sigma(X_1)$に対して、
          \[
            \EE[\gamma^{h}(X_1)I_G] = \EE[h(X_1, \cdots, X_r)I_G]
          \]
          を示せばよい。
          しかし、$\sigma(X_1) = \{X_{1}^{-1}(B) \mid B \in \BB(\RR)\}$
          であることを以前に証明している\footnote{36ページexercise}。
          したがって、$G = X_{1}^{-1}(B)$となる$B \in \BB(\RR)$
          が存在する。
          よって、
          \[
            I_G = I_{X_{1}^{-1}(B)}
          \]
          である。ここで右辺は
          \[
            I_{X_{1}^{-1}(B)} = I_B(X_1)
          \]
          だから、(c)の式を確認できれば主張の式を証明できたことになる。

      \subsubsection{Fubiniでの証明について}
          68ページの補題を
          $h \colon \RR^r \to \RR$というボレル可測関数$h$
          に対して使っている。
          2行目でFubiniの定理を用いている。
          \begin{align*}
            (\text{(c)の左辺})
            &= \int_{x \in \RR^r}h(x)I_B(x_1)(\Lambda_1 \times \Lambda_2 \times \cdots \Lambda_r)(dx) \\
            &= \int_{x_1 \in \RR}\int_{y \in \RR^{r-1}}h(x_1,y)I_B(x_1)(\Lambda_2 \times \cdots \Lambda_r)(dy)\Lambda_1(dx_1)\\
            &=\int_{x_1 \in \RR}\int_{y \in \RR^{r-1}}h(x_1,y)(\Lambda_2 \times \cdots \Lambda_r)(dy)I_B(x_1)\Lambda_1(dx_1)\\
            &= \int_{x_1 \in \RR}\gamma^{h}(x_1)I_B(x_1)\Lambda_1(dx_1)\\
            &= \EE[\gamma^h(X_1)I_{B}(X_1)]
          \end{align*}
          この証明独立性使ってるのかよくわかんないんだけど。

      \subsubsection{単調族定理での証明}
          もうちょい式を使って書いてくれって思った。
          \[
            \mathcal{H} := \{h \in b\BB^r \mid h \text{は(c)を満たす。}\}
          \]
          まず以下のことを示す。
            \begin{itemize}
              \item $\mathcal{H}$は$\RR$上のベクトル空間
              \item 定数関数$1$は$\mathcal{H}$に含まれる
              \item $\mathcal{H}$の非負関数列$(f_n)$が有界関数$f$に収束するなら、$f \in \mathcal{H}$
            \end{itemize}
          最初の二つは多分計算できるので実際に書いてみるとよいでしょう。
          三つめも多分計算できます。$\lim$を交換するときに(DOM)を使うことに注意しよう。
          \begin{align*}
            \EE[\gamma^f(X_1)I_B(X_1)]
            &= \EE[\EE[f(X_1,X_2, \cdots X_r)]I_B(X_1)]\\
            &= \EE[\EE[\lim_{n \to \infty}f_n(X_1,X_2, \cdots X_r)]I_B(X_1)]\\
            &= \EE[\lim_{n \to \infty}\EE[f_n(X_1,X_2, \cdots X_r)]I_B(X_1)]\\
            &= \lim_{n \to \infty}\EE[\EE[f_n(X_1,X_2, \cdots X_r)]I_B(X_1)]\\
            &= \lim_{n \to \infty}\EE[f_n(X_1,X_2, \cdots X_r)I_B(X_1)]\\
            &= \EE[\lim_{n \to \infty}f_n(X_1,X_2, \cdots X_r)I_B(X_1)]\\
            &= \EE[f(X_1,X_2, \cdots X_r)I_B(X_1)]
          \end{align*}

          $\BB^r$はもちろん$\pi$-systemです。
          また、$\sigma(\BB^r) = \BB^r$です。
          よって、次を示せば単調属定理を用いると証明が完了します。
          \begin{itemize}
            \item $\mathcal{H}$は$\BB^r$のすべての定義関数を含んでいる。
          \end{itemize}

        $A \in \BB^r$とする。
        $A_1,A_2,\cdots,A_r \in \BB^r$があって、
        $A = A_1 \times A_2 \times \cdots \times A_r$と書けます。
        \begin{align*}
          \text{(c)の右辺}
          &= \EE[\gamma^{I_A}(X_1)I_B(X_1)] \\
          &= \EE[\EE[I_A(X_1,X_2, \cdots ,X_r)]I_B(X_1)] \\
          &= \EE[\EE[1;A_1 \times A_2 \times \cdots \times A_r]I_B(X_1)]\\
          &= \EE[(\Lambda_1 \times \Lambda_2 \cdots \times \Lambda_r)(A_1 \times A_2 \times \cdots \times A_r)I_B(X_1)]\\
          &= (\Lambda_1 \times \Lambda_2 \cdots \times \Lambda_r)(A_1 \times A_2 \times \cdots \times A_r)\EE[I_B(X_1)]
        \end{align*}
        です。
        一方$X_1,\cdots , X_r$が独立であったことに気を付ければ(2行目で使っている)左辺は次のように計算できます。
        \begin{align*}
          \text{(c)の左辺}
          &= \EE[I_A(X_1,X_2, \cdots, X_r)I_B(X_1)] \\
          &= \EE[I_A(X_1,X_2, \cdots, X_r)]\EE[I_B(X_1)] \\
          &= (\Lambda_1 \times \Lambda_2 \cdots \times \Lambda_r)(A_1 \times A_2 \times \cdots \times A_r)\EE[I_B(X_1)]
        \end{align*}

    \subsection{9.11について}
      この節のタイトルが"Use of symmetry: an example"
      なんだから、対称性を使ったところは分かるように明記しておいてほしいと思いました。
      さりげなく使わないで。いや、まあ確かによく考えたらわかるけど。
      わかるけどさ...

      \subsubsection{3行目}
        \[
          \sigma(S_n,S_{n+1},\cdots) = \sigma(S_n,X_{n+1},X_{n+2},\cdots)
        \]
        について。
        \begin{proof}
          ($\subset$について)\\
          $m > n$とする。
          \[
            S_m = S_n + \sum_{k = n+1}^m X_k
          \]
          と表されるから、$S_m$は右辺で可測。

          ($\supset$について)\\
          $m > n$とする。
          \[
            X_m = S_m - S_{m - 1}
          \]
          だから、$X_m$は左辺で可測。
        \end{proof}

      \subsubsection{6行目}
        \[
          \sigma(X_{n+1},X_{n+2},\cdots), \sigma(X_1,S_n)
        \]
        が独立なこと。
        \begin{proof}
          $\sigma(X_{n+1},X_{n+2},\cdots)$と$\sigma(X_1,\cdots,X_n)$が独立であることを示せばよい。
          ところが、これは4章の0-1法則で証明済み。
        \end{proof}

      \subsubsection{9行目}
        \[
          \EE[X_1 \mid \mathcal{G}] = \EE[X_1 \mid S_1]
        \]
        について。
        \begin{proof}
          \[
          \sigma(X_1,S_n) = \sigma(\sigma(X_1),\sigma(S_n))
          \]
          より、
          $\sigma(X_{n+1},X_{n+2},\cdots)$と$\sigma(\sigma(X_1),\sigma(S_n))$
          は独立。
          よって(9.7.k)より、
          \begin{align*}
            \EE[X_1 \mid \mathcal{G}]
            &= \EE[X_1 \mid \sigma(S_n,X_{n+1},X_{n+2},\cdots)] \\
            &= \EE[X_1 \mid \sigma(\sigma(S_n),\sigma(X_{n+1},X_{n+2},\cdots))]\\
            &= \EE[X_1 \mid \sigma(S_n)]
          \end{align*}
        \end{proof}

      \subsubsection{12行目からの計算}
        $\pi_i \colon \RR^r \rightarrow \RR$を第$i$成分への射影とする。
        $B$は$\BB$の任意の元である。
        \begin{align*}
          \EE[X_1;S_n \in B]　
          &= \EE[\pi_1(X_1,X_2,\cdots,X_r);S_n \in B]\\
          &= \int_{s_n \in B}x_1 (\Lambda \times \Lambda \times \cdots \times \Lambda)(dx)\\
          &= \int \cdots \int_{s_n \in B}x_1 \Lambda(dx_1)\Lambda(dx_2)\cdots\Lambda(dx_r)\\
          &= \int \cdots \int_{s_n \in B}x_2 \Lambda(dx_2)\Lambda(dx_1)\cdots\Lambda(dx_r)\\
          &= \EE[\pi_2(X_1,X_2,\cdots,X_r);S_n \in B]\\
          &= \EE[X_2;S_n \in B]
        \end{align*}
        3行目から4行目の変形で対称性を用いた。
        ($x_1,x_2$を入れ替えても変わらない。)

      \subsubsection{結局何が分かった}
        条件付き期待値でも大数の法則みたいなの成り立ってるよね！

  \section{Chapter 10}
    \subsection{10.1}
      \subsubsection{6行目}
        $\mathcal{F}_{\infty}$の定義に、$\sigma$が付いているのは、
        $\bigcup_n \mathcal{F}_{\infty}$だけではダメ。
        例えば、
      \begin{gather*}
        \Omega = \{a,b,c\}\\
        \mathcal{F}_1 = \{\emptyset, \{a\}, \{b, c\}, \Omega\}\\
        \mathcal{F}_2 = \{\emptyset, \{b\}, \{a, c\}, \Omega\}
      \end{gather*}
      とおく。$\mathcal{F}_1, \mathcal{F}_2$は当然$\sigma$-alg.であるが、
      $\mathcal{F}_1 \cup \mathcal{F}_2$は$\sigma$-alg.にならない。

    \subsection{10.2}
      \subsubsection{気を付けておきたいこと}
        adopted processにおいては$X_{n+1}$が$\mathcal{F}_n$可測かどうかはわからない。
        一方、$s < t$ならば$\mathcal{F}_s \subset \mathcal{F}_t$だから、
        $X_s$は$\mathcal{F}_t$可測であることは分かる。

    \subsection{10.3}
      \subsubsection{94ページ下から14行目}
        本文では"It is important to note that ..."とかいてあるところ。
        主張を改めて書いておくと次のようになる。
        この主張、本に証明全くないのウケる。
        \begin{prop*}
          $X_0 \in \mathcal{L}^1(\Omega, \mathcal{F}, \PP)$
          であるような過程$X$がある。
          この$X$がマルチンゲールであることと、
          過程$(X - X_0)$がマルチンゲールであることは同値。
        \end{prop*}
        \begin{proof}
          $X$はマルチンゲールと仮定する。
          $X_n,X_0$はともに$\mathcal{F}_n$可測だから、
          $X_n - X_0$は$\mathcal{F}_n$可測。
          よって、$(X - X_0)$はadopted process。
          $n \ge 1$に対して、
          \[
            |X_n - X_0| \leq |X_n| + |X_0|
          \]
          より(三角不等式)、
          \[
            \EE[|X_n - X_0|] \leq \EE[|X_n|] + \EE[|X_0|] < \infty
          \]
          だから(右側の不等式は$X$がマルチンゲールであることからわかる)、
          $X_n - X_0$は可積分。
          そして、$n \ge 1$に対して$X_0$は$\mathcal{F}_{n-1}$可測であることに注意すると、
          \begin{align*}
            \EE[X_n - X_0 \mid \mathcal{F}_{n-1}]
            &= \EE[X_n \mid \mathcal{F}_{n-1}] - \EE[X_0 \mid \mathcal{F}_{n-1}] \\
            &= X_{n-1} - X_0
          \end{align*}
          よって、$X - X_0$はマルチンゲール。

          一方、$X - X_0$がマルチンゲールだと仮定する。
          $X_n - X_0$および$X_0$は$\mathcal{F}_n$可測であり、
          \[
            X_n = X_n - X_0 + X_0
          \]
          なので、$X_n$は$\mathcal{F}_n$可測。
          したがって、$X$はadopted processである。
          \begin{align*}
            \infty &> \EE[|X_n - X_0] \ge \EE[|X_n] - \EE[|X_0|]
          \end{align*}
          なので、$X_0 \in \mathcal{L}^1$より
          \[
            \EE[|X_n|] \leq \EE[|X_0] + \EE[|X_n - X_0] < \infty
          \]
          が分かる。よって、各$X_n$は可積分。
          $\EE[X_n \mid \mathcal{F}_{n-1}] = \EE[X_n - X_0 + X_0 \mid \mathcal{F}_{n-1}]$より、
          先ほどと似たような計算を経ることにより、
          \[
            \EE[X_n \mid \mathcal{F}_{n-1}] = X_{n-1}
          \]
          がわかる。よって$X$はマルチンゲールである。
        \end{proof}

    \subsection{10.4}
      \subsubsection{(a)の例について}
        マルチンゲールの3つ目の条件は本に書いてある通り。
        しかし、一つ目と二つ目の条件の確認は省略されているのでちゃんとしておこう。
        とはいえ、簡単で、$(S_n)$がadopted processなことは、今回のfiltrationの定義から明らか。
        $\EE[|S_n|] < \infty$であることは、$\EE[|X_n|] < \infty$という仮定から明らか。
      \subsubsection{(b)の例について}
          (9.7.j)を用いているが、ちゃんと使えるか条件を確認しておかないといけない。
          その条件は、
          \[
            X \in (m\mathcal{F})^+ ,\, Z \in (m\mathcal{G})^+, \, \EE[X] < \infty , \, \EE[ZX] < \infty
          \]
          ここで、$\mathcal{F}$とは、確率空間$(\Omega, \mathcal{F},\PP)$の$\mathcal{F}$で、
          $\mathcal{G}$とは$\mathcal{F}$の部分$\sigma$-alg.のこと。
          (b)の場合だと、$X$に相当するものが$X_n$、
          $Z$に相当するものが、$M_{n-1}$である。
          だから、
          \[
            X_n \in (m\mathcal{F})^+ ,\, M_{n-1} \in (m\mathcal{G})^+, \, \EE[X_n] < \infty , \, \EE[M_{n-1}X_n] < \infty
          \]
          を確認すればよい。

      \subsubsection{気づいたこと}
        (a),(b)はそれぞれ環の加法単位元と乗法単位元に対応してる感じがあった。
        平均が$0$というのは環の加法の演算においては$0$が単位元であることに対応してて、
        平均が$1$というのは(非負という条件も付くが)、環の乗法の置いては$1$が単位元であることに対応してそう。

        マルチンゲールがそうやって代数とつながってるのかは分かんないね。
        今回だけの偶然かもしれない。

      \subsubsection{(c)の例について}
        なんかもうここまでadopted processと可積分性確認されないのおもろいな。(なんもおもろくないが(ちゃんと書けや))

        \begin{align*}
          |\EE[\xi \mid \mathcal{F}_n]|
          &=|\EE[\xi^+ - \xi^- \mid \mathcal{F}_n]|\\
          &= |\EE[\xi^+ \mid \mathcal{F}_n] - \EE[\xi^- \mid \mathcal{F}_n]|\\
          &\leq |\EE[\xi^+ \mid \mathcal{F}_n]| + |\EE[\xi^- \mid \mathcal{F}_n]|
        \end{align*}
        だから、
        \begin{align*}
          \EE[|M_n|]
          &\leq \EE[|\EE[\xi^+ \mid \mathcal{F}_n]| + |\EE[\xi^- \mid \mathcal{F}_n]|]\\
          &= \EE[\EE[\xi^+ \mid \mathcal{F}_n]] + \EE[\EE[\xi^- \mid \mathcal{F}_n]]\\
          &= \EE[\xi^+] + \EE[\xi^-]\\
          &= \EE[\xi^+ + \xi^-]\\
          &= \EE[|\xi |] < \infty \quad (\xi \in \mathcal{L}^1)
        \end{align*}

    \subsection{10.5}
      とくにないです。

    \subsection{10.6}
      英語が微妙にわからないやつ。

      "Your winnings on game $n$ are $C_n(X_n - X{n-1})$ and ..."
      はおそらく、
      「第$n$ゲーム終了時にもらえるお金は"$C_n(X_n - X{n-1})$"
      (これは負の数\footnote{もらえるお金が負の数ということは、お金を失ったということ}も含めて考えている)であるとすると」
      という意味だと思われる。

    \subsection{10.7}
      ここの証明もサラッとしか書かれていないな？
      もっと丁寧に言ってくれないと僕ちゃん見落としちゃうぞ？
      \subsubsection{(i)の証明の補完}
        $C_n \EE[X_n - X_{n-1} \mid \mathcal{F}_{n-1}] \leq 0$は、
        $C_n$が非負で、submartingaleであることと(9.7.b)から、
        \[
          \EE[X_n - X_{n-1} \mid \mathcal{F}_{n-1}] \leq X_{n-1} - X_{n-1} = 0
        \]
        と計算できるから。
        また、($C \bullet X$)がadopted processであることについては、
        $C_{n-1}$は$\mathcal{F}_{n-2}$可測であり、filtrationの定義から
        $C_{n-1}$は$\mathcal{F}_{n-1}$可測でもある。
        可積分性については、次のように計算できる。
        \begin{align*}
          \EE[|Y_n|]
          &= \EE[|\sum_{k=1}^n C_k(X_k - X_{k-1})|] \\
          &\leq \EE[\sum_{k=1}^n | C_k(X_k - X_{k-1})|] \\
          &= \sum_{k=1}^n \EE[| C_k(X_k - X_{k-1})|] \\
          &\leq \sum_{k=1}^n \EE[|C_k X_k| + |C_k X_{k-1}|] \\
          &\leq \sum_{k=1}^n (\EE[K|X_k|] + \EE[K|X_{k-1}|]) < \infty
        \end{align*}
        なお、ここで1行目から2行目は三角不等式を用いている。
        3行目から4行目は$|a - b| \leq |a| + |b|$を用いている。
        4行目から5行目はprocess $C$が有界だから$C_k < K $と
        一様に上から押さえられていることを用いている。
        5行目の$< \infty$は、各$X_k$が可積分であることを用いている。

      \subsubsection{(ii)の証明の補完}
        $C_n$が非負であることはsubmartingaleの時に用いた。
        (i)の証明でmartingaleの時の証明をそのまま流用すればよい。

      \subsubsection{(iii)の証明の補完}
        (9.7.j)を用いるための条件として、
        \[
          p>1, \, \frac{1}{p} + \frac{1}{q} = 1, \, X \in \mathcal{L}^p, \, Z \in \mathcal{L}^q
        \]
        があった。今回は$p = q =2$の場合。他は同様。
        可積分性は、$X_k \in \mathcal{L}^2$より、$X_k \in \mathcal{L}^1$なので、
        $\EE[|Y_n|] < \infty$がわかる。

    \subsection{10.8}
      \subsubsection{$L$がstopping timeではないかもしれないこと}
        例えば$L = 6$という集合は次のように考えられる。
        $n < 6$の時は、$A_n \in B$であることはどうでもよい。
        $n \ge 7 $の時は$A_n \notin B$であることが必要である。
        したがって、次にように考えることができる。
        \begin{align*}
          \{L = 6\} &= \{A_6 \in B, \, A_7 \notin B, \, \cdots ,\, A_{10} \notin B\}\\
          &= \{A_6 \in B\} \cap \{A_7 \notin B\} \cap \cdots \cap \{A_{10} \notin B\} \in \mathcal{F}_6 \quad \text{(???)}
        \end{align*}
        $\{L = 6 \} \in \mathcal{F}_6$ならば$L$は stopping time となる。
        しかしながら、$A$は adopted process だから$A_7$
        は$\mathcal{F}_6$可測関数かどうかまでは分からない。
        ということは、
        \[
          \{A_7 \notin B\} \in \mathcal{F}_6
        \]
        かどうかは判断がつかない。(これは$A_8,A_9,A_{10}$も同様)
        したがって、$L$は stopping time であるとは断言することができない。
        本文で "unless $A$ is freaky" とカッコ付けで書かれているのは、
        「$A$が極端な過程なため、$L$が stopping time になってしまうような場合を除けば」というニュアンス。

    \subsection{10.9}
      \subsubsection{$(C^{(T)} \bullet X)_n = X_{T \wedge n} - X_0$なこと}
        場合分けをして考える。
        しかし、$T$そのものは写像なので単に「$T < n$の場合」とすることはできない\footnote{こうしてしまうと「$T$は上に有界」という主張になってしまう。}。
        まず初めに$\omega \in \Omega$を一つ固定して、
        \begin{enumerate}
          \item $T(\omega) < n$の場合
          \item $T(\omega) \ge n$の場合
        \end{enumerate}
        として計算よう。

      \subsubsection{$\ZZ$上のsimple random walk が martingale}
        丁寧に書くところと書かないところの差が激しくないですか？

        \begin{def*}[$\ZZ$上の simple random walk]
          $(\xi_i)_{i \leq 1}$は$i.i.d$の独立な$\{-1, 1\}$-値確率変数とする。
          任意の$\xi_i$について、
          \[
            \PP(\xi_i = 1) = \PP(\xi_i = -1) = \frac{1}{2}
          \]
          とする。
          確率変数列$(X_n)_{n \ge 0}$を次のように定義する。
          \begin{align*}
            &X_0 := 0 \\
            &X_{n+1} = X_n + \xi_{n+1}
          \end{align*}
          確率過程$(X_n)_{n \ge 0}$を$\ZZ$上の simple random walk という。
        \end{def*}

        $X$を$\ZZ$上の simple random walk とする。
        $X$はmartigaleになる。
        martingale であることを示すためには filtraion が必要である。
        今回のfiltration は natural filtration 、すなわち、
        \[
          \mathcal{F}_n = \sigma(X_0,X_1, \cdots , X_n)
        \]
        である。simple random walk の定義から、
        \begin{align*}
          \mathcal{F}_n &= \sigma(X_0,X_1, \cdots , X_n)\\
          &= \sigma(0, \xi_1, \cdots ,\xi_n) \\
          &= \sigma(\xi_1, \cdots ,\xi_n)
        \end{align*}
        である。

        $X$は natural filtration の定義から adopted process である。
        各$n$に対して
        \[
          X_n = \sum_{i = 1}^{n} \xi_i \leq n
        \]
        だから、
        \[
          \EE[|X_n|] < \infty
        \]
        である。最後に、
        \begin{align*}
          \EE[X_{n+1} \mid \mathcal{F}_n] &= \EE[X_{n} + \xi_{n + 1} \mid \mathcal{F}_n]\\
          &= \EE[X_{n} \mid \mathcal{F}_n] + \EE[\xi_{n + 1} \mid \mathcal{F}_n] \\
          &= X_{n} + \EE[\xi_{n + 1}] \\
          &= X_{n} + 1 \times \frac{1}{2} + (-1) \times \frac{1}{2}\\
          &= X_{n}
        \end{align*}
        したがって、$X$は martingale である。

    \subsection{10.10}
      ここひどい。
      $X_T$の定義が書かれていないので何とも議論ができない。
      $T(\omega) < \infty$のときは問題なく定義できるでしょうが、
      $T(\omega) = \infty$のとき、つまり$X_{\infty}$の定義が書かれていない。
      \footnote{Chapter 11のマルチンゲールの収束定理を見れば定義が分かるかもしれないが、
      それをするなら先にその収束定理をかけよ。}
      それ以外にも抜けているところが多いので、
      証明をすべて書いていきます。

      \subsubsection{almost surely と almost everywhere (再確認)}
        この本によると、これらの二つは微妙に定義が異なります。

        $\omega \in \Omega$ごとに真偽が決まる命題$P(\omega)$
        がある。単に$P$と略記する。
        $P$が$\Omega$上 almost everywhere で成立するとは、
        $P$が成立しない集合が可測集合かつ、その測度が0であること。

        $P$が$\Omega$上 almost surely で成立するとは、
        $P$が成立する集合の測度(確率)が$1$であること。

        前者は全ての測度空間において定義できる概念で、
        後者は確率論専用の概念です。
        すなわち、almost surely というのは確率空間があるときにのみ
        導入できる概念です。

      \subsubsection{証明}

        \begin{proof}
        (a)の証明。

        [準備]
        仮定より、$(X_{T \wedge n})$はsupermartingaleになるから、
        各$n \in \NN$に対して、$X_{T \wedge n}$は可積分である。
        また、10.9の定理より、
        \[
          \EE[X_{T \wedge n}] \leq \EE[X_0]
        \]
        がすべての$n \in \NN$について成立している。

        [(i)が成り立つ場合]
        $T$は有界なので、ある$N \in \NN$が存在して、
        $T(\omega) \leq N$となる。
        よって、$X_{T \wedge N} = X_T$となる。
        したがって、
        \[
          \EE[X_T] = \EE[X_{T \wedge N}] \leq \EE[X_0]
        \]
        また、$|X_{T \wedge n}| = |X_T|$より、
        $X_T$は可積分であることが分かる。

        [$T$がfinite (a.s)ならば$\lim_{n \to \infty}X_{T \wedge n} = X_T $(a.s)であること]
        $\omega \in \{T < \infty\}$ ならば明らかに
        $\lim_{n \to \infty}X_{T(\omega) \wedge n}(\omega) = X_{T(\omega)}(\omega) $
        そして、$T$ finite (a.s)なので、$\PP(\{T < \infty\}) = 1$
        である。
        さて、$\{\omega \mid \lim_{n \to \infty}X_{T(\omega) \wedge n}(\omega) = X_{T(\omega)}(\omega)\}$
        は「可測集合」であるが
        \footnote{らしいけど、これまじ？$X_T$の定義がないとやっぱ無理ちゃう？}、
        \[
          \{T < \infty\} \subset \{\omega \mid \lim_{n \to \infty}X_{T(\omega) \wedge n}(\omega) = X_{T(\omega)}(\omega)\}
        \]
        であるから、測度の単調性より、
        \[
          \PP(\{\omega \mid \lim_{n \to \infty}X_{T(\omega) \wedge n}(\omega) = X_{T(\omega)}(\omega)\}) = 1
        \]
        となる。

        [(ii)が成立しているとき]
        先ほどの議論と$T$はfinite (a.s)であるという仮定から
        \[
          \lim_{n \to \infty}X_{T \wedge n} = X_T
        \]
        が almost surely で成立する。
        また、過程$X$は有界より(BDD)を使うことができる。したがって、
        \[
          \lim_{n \to \infty}\EE[X_{T \wedge n}] = \EE[X_T]
        \]
        がなりたつ。
        よって、
        \begin{align*}
          \EE[X_{T \wedge n}] &\leq \EE[X_0] \\
          \lim_{n \to \infty}\EE[X_{T \wedge n}] &\leq \lim_{n \to \infty}\EE[X_0] \\
          \EE[X_T] &\leq \EE[X_0]
        \end{align*}
        $X_T$の可積分性は次のように示す。
        \begin{align*}
          \EE[|X_T|] &= \int_{\{T < \infty\}}|X_T|\PP(d\omega) + \int_{\{T = \infty\}}|X_T|\PP(d\omega) \\
          &= \int_{\{T < \infty\}}|X_T|\PP(d\omega) + 0\\
          &= \int_{\{T < \infty\}}|X_T|\PP(d\omega)
        \end{align*}
        であるが、ここで$X$が有界であるという仮定と、
        $\omega \in \{T < \infty\}$であることから
        次のような計算ができる。
        ただし、以下で$K$とは、$X$を上から押さえている定数。
        \begin{align*}
          |X_{T(\omega) \wedge n}(\omega)| &\leq K \\
          \lim_{n \to \infty}|X_{T(\omega) \wedge n}(\omega)| &\leq K \\
          |X_{T(\omega)}(\omega)| &\leq K
        \end{align*}
        したがって、
        \[
          \EE[|X_T|] \leq K < \infty
        \]
        よって、$X_T$は可積分である。

        [(iii)が成り立つとき]
        このとき、$T$は finite (a.s.) である。
        これは背理法を用いれば$\EE[T] < \infty$に反していることがすぐにわかる。
        (iii)の仮定を使えば、
        \[
          |X_{T \wedge n} - X_0| = |\sum_{k=1}^{T \wedge n}(X_k - X_{k-1})| \leq TK
        \]
        ここで$K$は定数で、$\EE[T] < \infty$より、$\EE[TK] < \infty$。
        よって、(DOM)より。
        \[
          \EE[|(X_{T \wedge n}) - X_0) - (X_T -X_0)|] \rightarrow 0
        \]
        すなわち、
        \begin{align*}
          \EE[|X_{T \wedge n} -X_T|] \rightarrow 0 \\
          \lim_{n \to \infty}\EE[X_{T \wedge n}] = \EE[X_T]
        \end{align*}
        よって(ii)と同様に、$\EE[X_T] \leq \EE[X_0]$となる。
        $X_T$の可積分性は次のように示す。
        \[
          |X_{T \wedge n} - X_0| \ge |X_{T \wedge n}| - |X_0|
        \]
         であり、
         \[
            |X_{T \wedge n} - X_0| \leq TK
         \]
         なので、
         \begin{align*}
            |X_{T \wedge n}| - |X_0| &\leq TK \\
            |X_{T \wedge n}| &\leq TK + |X_0|\\
            \lim_{n \to \infty}|X_{T \wedge n}| &\leq \lim_{n \to \infty}(TK + |X_0|)\\
            |X_{T}| &\leq TK + |X_0|\\
            \EE[|X_{T \wedge n}|] &\leq \EE[TK + |X_0|] < \infty
         \end{align*}

         以上によりすべての主張を証明できた。

         (b)の証明。

         $X$がマルチンゲールだから$-X$もマルチンゲール。
         よって(a)を適用すればよい。
       \end{proof}

      \subsubsection{系について}

        \begin{cor}
        $M$はマルチンゲールで、各$n$に対して$M_n - M_{n-1}$は一様に
        $K_1 \in \RR^+$で押さえられている。
        すなわち、
        \[
          \exists K_1 \in \RR, \forall n \in \NN, \forall \omega \in \Omega, |M_n(\omega) - M_{n-1}(\omega)| \leq K_1
        \]
        とする。$C$はprevisible process\footnote{filtrationは与えられているものとする}で、$K_2 \in \RR^+$で一様に抑えられているとする。
        $T$はstopping time で、$\EE[T] < \infty$とする。
        このとき、$\EE[(C \bullet M)_T] = 0$となる。
        \end{cor}

        \begin{proof}
        $M$はマルチンゲールで、$C$は有界なprevisible process なので、
        10.7節の(b)より、$(C \bullet M)$は$(C \bullet M)_0 = 0$
        であるようなマルチンゲールである。
        また、
        \[
          |(C \bullet M)_n - (C \bullet M)_{n-1}| = |C_n(M_n - M_{n-1})| \leq K_1K_2
        \]
        仮定より、
        \[\EE[T] < \infty\]
        よって、任意抽出定理の(iii)の条件を満たしているので、
        10.10(b)より、
        \[
          \EE[(C \bullet M)_T] = \EE[(C \bullet M)_0] = \EE[0] = 0
        \]

        \end{proof}

        \begin{cor}\label{10.10d}
          $X$が非負supermartingaleで$T$がstopping time で、a.s.で有限であるとする。このとき、
          \[\EE[X_T] \leq \EE[X_0]\]
        \end{cor}

        \begin{proof}
          $X$がsupermartingaleより、$\EE[X_{T \wedge n}] \leq \EE[X_0]$
          である。$X$が非負より、$X_{T \wedge n}$も非負。
          また、$T$はa.s.で有限より、
          $X_{n \wedge T} \rightarrow X_T$がa.s.で成立する。
          よって、FATOUの補題より、
          \begin{align*}
            \EE[\liminf_{n \to \infty}X_{T \wedge n}] &\leq \liminf_{n \to \infty}\EE[X_{T \wedge n}]\\
            \EE[X_T] &\leq \liminf_{n \to \infty}\EE[X_0]\\
            &=\EE[X_0]
          \end{align*}
        \end{proof}

      \subsubsection{やらかしたミス}
        せや！
        \[
          X \leq Y \Rightarrow \EE[X \mid \mathcal{F}] \leq \EE[Y \mid \mathcal{F}]
        \]
        なんやから、対偶を取ったら
        \[
          \EE[X \mid \mathcal{F}] \leq \EE[Y \mid \mathcal{F}]  \Rightarrow X \leq Y
        \]
        だから、系\ref{10.10d}はこれですぐにしめせるやんけ！ｗ

        almost surelyが付いた命題の否定命題を考えるときは気をつけましょう。

    \subsection{10.11}
      本文には巻末の演習問題集のE10.5を参考にしなさいと書いてあります。
      \subsubsection{E10.5の証明}
        \begin{proof}
          帰納法で示す。

          [$n=1$のとき]
          $\PP(T > N) = 1 - \PP(T \leq N)$である。
          $\PP(T \leq M \mid \mathcal{F}_0)$は
          $\EE[I_{\{T \leq N\}} \mid \mathcal{F}_0]$
          の一変形であり、仮定より、
          \[
            \PP(T \leq N \mid \mathcal{F}_0) >  \varepsilon \quad (a.s.)
          \]
          となる$N \in \NN, \varepsilon > 0$が存在する。
          したがって、
          \[
            -\PP(T \leq N \mid \mathcal{F}_0) < - \varepsilon \quad (a.s.)
          \]
          である。
          条件付き平均の定義より、
          \[
            \int_{\Omega} \PP(T \leq N \mid \mathcal{F}_0) d\PP
            = \int_{\Omega}I_{\{T \leq N\}}d\PP
            = \PP(T \leq N)
          \]
          である。したがって、
          \[
            -\varepsilon
            > \int_{\Omega}(-\PP(T \leq N \mid \mathcal{F}_0))
            = -\PP(T \leq N)
          \]
          よって、
          \[
            1 - \PP(T \leq N) < 1 - \varepsilon
          \]
          すなわち、
          \[
            \PP(T > N) < \varepsilon
          \]

          $n = k(\leq 1)$の時成立すると仮定。$T$はstoppinng timeより、
          \[
            \{T \leq kN\} \in \mathcal{F}_{kN}
          \]
          したがって、
          \[
            \{T \leq kN\}^c = \{T > kN\} \in \mathcal{F}_{kN}
          \]
          ところで、
          \[
            \PP(T \leq kN + N \mid \mathcal{F}_{kN}) > \varepsilon \quad (a.s.)
          \]
          より、
          \begin{align*}
            1 - \PP(T \leq kN + N \mid \mathcal{F}_{kN}) &< 1 - \varepsilon \quad (a.s.) \\
            \PP(T > kN + N \mid \mathcal{F}_{kN}) &< 1 - \varepsilon \quad (a.s.)
          \end{align*}
          $\PP(T > kN + N \mid \mathcal{F}_{kN})$は
          $\EE[I_{\{T > kN + N\}} \mid \mathcal{F}_{kN}]$
          の一変形であることに注意すれば、
          \begin{align*}
            \int_{T > kN}\PP(T > kN + N \mid \mathcal{F}_{kN})d\PP
            &< \int_{T > kN}(1 - \varepsilon )d\PP \\
            \int_{T > kN}I_{\{T > kN + N\}}d\PP
            &< (1 - \varepsilon )\PP(T > kN) \\
            \int_{\Omega} I_{\{T > kN + N\} \cap \{T > kN\}}d\PP
            &< (1 - \varepsilon )(1 - \varepsilon)^k \\
            \PP(\{T > kN + N\} \cap \{T > kN\})
            &\leq (1 - \varepsilon)^{k+1}\\
            \PP(T > (k + 1)N)
            &\leq (1 - \varepsilon)^{k+1}\\
          \end{align*}
        \end{proof}

      \subsubsection{$\EE[T] < \infty$の証明}
        \begin{proof}
          \begin{align*}
            \EE[T] =& 0 \times \PP(T = 0) \\
            &+ 1 \times \PP(T = 1) + 2 \times \PP(T = 2) + \cdots + N \times \PP(T = N)\\
            &+ (N + 1) \times \PP(T = N + 1) + (N + 2) \times \PP(T = N + 2) + \cdots + 2N \times \PP(T = 2N)\\
            &+ (2N + 1) \times \PP(T = 2N + 1) + (2N + 2) \times \PP(T = 2N + 2) + \cdots + 3N \times \PP(T = 3N)\\
            &+ (3N + 1) \times \PP(T = 3N + 1) + \cdots
          \end{align*}
          と書けるから、
          \[
            \EE[T] \leq N\PP(0<T\leq N) + 2N\PP(N< T \leq 2N) + \cdots
          \]
          とできる。ここで、$l = 1,2,3,\cdots$に対して
          \[
            \PP(lN < T \leq (l + 1)N) \leq \PP(lN < T) \leq (1 - \varepsilon)^l
          \]
          なので、
          \[
            \EE[T] \leq
            N\PP(0 < T \leq N)
            + \sum_{l = 1}^{\infty}(l + 1)N(1 - \varepsilon)^l
          \]
          とできる。
          右辺の無限級数は有限の値に収束する。
          よって$\EE[T] < \infty$
        \end{proof}

        \subsubsection{ABRACADABRAについて}
          ごめんやってない。

    \subsection{10.12}
      \subsubsection{$\text{sech}$とは}
          見慣れない記号ですが定義は以下の通り\footnote{\LaTeX でうまいこと出力するの分からなかったから適当に誤魔化しています。}。
        \[
          \text{sech} \, \theta = \frac{1}{\cosh \theta}
          \]

      \subsubsection{p.102 $\blacktriangleright$ について}
          "Now insisit that $\theta > 0$"の意味は「ここで$\theta > 0$とする」。
          これたぶん初めから$\theta > 0$でやっておけばいいと思った。
          この条件は後々聞いてくるので必要な条件です。

          \subsubsection{p.102 $\blacktriangleright$ の一行下について}
          \[
          \exp(\theta S_{T \wedge n}) \leq e^{\theta}
          \]
          と主張している。これを言うためには
          \[
          S_{T \wedge n} \leq 1
          \]
          を確認しておく必要がある。
          $T(\omega) < \infty$の場合と、$T(\omega) = \infty$の場合に
          場合分けしてそれぞれ調べる。

          その次に、$M_{T \wedge n}^{\theta} < e^{\theta}$であるのは、
          すぐ上で確認したように
          \[
          \exp(\theta S_{T \wedge n}) \leq e^{\theta}
          \]
          であることと、$\theta > 0$より、
          \[
          \text{sech} \, \theta < 1
          \]
          である\footnote{詳しい計算は微分頑張ったらいけるはず。}ことよりわかる。

      \subsubsection{102ページ下から9行目}
        こう書いていたら分かりやすいと思います。

        $M_{T}^{\theta}$を以下のように定める。
        \begin{equation*}
          M_{T}^{\theta}(\omega) =
          \begin{cases}
            M_{T(\omega)}^{\theta}(\omega) & (T(\omega) < \infty) \\
            0 & (T(\omega) = \infty)
          \end{cases}
        \end{equation*}
        このとき、
        \[
          \lim_{n \to \infty}M_{T \wedge n}^{\theta} = M_{T}^{\theta}
        \]
        が成立する\footnote{ここでは(a.s.)の意味ではなく、通常の意味での各点収束}。
        この収束の証明は次の通り。
        \begin{proof}
          $\omega \in \{ T < \infty\}$の場合は明らか。
          $\omega \in \{ T = \infty\}$の場合、
          \begin{align*}
            M_{T \wedge n}^{\theta}(\omega)
            &= M_n^{\theta}(\omega)\\
            &= (\text{sech}\, \theta)^n e^{\theta S_n(\omega)}\\
            &\leq (\text{sech}\, \theta)^n e^{\theta}\\
            & \rightarrow 0 \quad (n \rightarrow \infty)
          \end{align*}
        \end{proof}

      \subsubsection{102ページ下から6行目の式の右辺}
        しれっと$(\text{sech}\,(\theta))^T$が出てきているけれど、
        定義が明記されていないので、エスパー能力を発揮して
        適切な定義を察してあげないといけません。
        おそらく次のように解釈するのが自然でしょう。
        \begin{def*}
          \begin{equation*}
            (\text{sech}\, \theta)^T =
            \begin{cases}
              (\text{sech}\, \theta)^{T(\omega)} & (T(\omega) < \infty)\\
              0 & (T(\omega) = \infty)
            \end{cases}
          \end{equation*}
        \end{def*}
        こうしてきちんと定義をしておかないと、
        \[
          (\text{sech}\, \theta)^{\infty}
        \]
        という謎の計算をどう処理するのかわからなくなってしまいます。

        なおこのように新しく記号を導入したので、
        \[
          M^{\theta}_T = (\text{sech}\, \theta)^T \exp{(\theta S_{T})}
        \]
        が成立することを確かめておかなければなりません。
        (この確かめはそこまで難しくない。)

      \subsubsection{102ページ下から3行目}
        $\theta \downarrow 0$としていますが、ここ少し大雑把に書いてある。
        実際はこのようにしています。

        $n \ge 1$に対して、
        \[
          f_n(\omega ) :=
          \left(\text{sech}\, \frac{1}{n}\right)^{T(\omega)}
        \]
        とさだめ、
        \[
          f(\omega ) := I_{\{T < \infty \}}(\omega)
        \]
        と定義する。
        このとき、$f_n$は増加列で、すべての$\omega \in \Omega$について
        \[
          \lim_{n \to \infty}f_n(\omega) = f(\omega)
        \]
        が成り立つ。
        したがって、(MON)を使って、
        \begin{align*}
          \lim_{n \to \infty}e^{-\frac{1}{n}} &=
          \lim_{n \to \infty}\EE \Bigl[\left(\text{sech}\, \frac{1}{n}\right)^{T(\omega)} \Bigr] \\
          1 &= \lim \EE[f_n] \\
          1 &= \EE[\lim f_n] \\
          1 &= \EE[f] = \PP(T < \infty)
        \end{align*}

      \subsubsection{103ページ(c)の式の一番右辺}
        強マルコフ性を使わなくてもいけるのでは...。

        \[
          \text{sech}\, \theta = \alpha
        \]
        を$e^{-\theta}$について解くと、
        \[
          e^{-\theta} = \frac{1 \pm \sqrt{1 - \alpha^2}}{\alpha}
        \]
        と求められるが、いま$\theta > 0$という条件より、
        \[
          e^{-\theta} = \frac{1 + \sqrt{1 - \alpha^2}}{\alpha}
        \]
        はあり得ないことが分かってしまう。

      \subsubsection{103ページ上から6行目}
        $\sqrt{1 - \alpha^2}$を一般二項展開しよう。
        その後係数比較をすると
        \[
          \PP(T = 2m) = 0
        \]
        であることもついでに分かってしまう。

    \subsection{10.13}
      \subsubsection{103ページ下から9行目}
        確立測度を入れるためには$\sigma$-alg. が必要なわけですが、
        ここでは$2^E$がそれにあたります。

      \subsubsection{103ページ下から3行目}
        この形の条件付き確率でも
        マルコフ性成り立っていてほしいよねって言う式。
        証明は直観的には素直な感じですが、
        書いてみると面倒くさいなあというタイプの証明。

        \begin{proof}
           左辺は$\EE[Z_{n+1} = j \mid \mathcal{F}_n]$の一変形だから、
           \[
              \int_G I_{\{Z_{n+1} = j\}} d\PP^{\mu} = \int_G p(X_n ,j) d\PP^{\mu} \quad (\forall G \in \mathcal{F}_n)
           \]
           を示せばよい。

           当然ながら、
           $\omega \in G \Rightarrow Z_n(\omega) \in Z_n(G)$
           であるから、$G$は次のように書くことができる。
           \[
            G = \bigcup_{a_n \in Z_n(G)} \cdots \bigcup_{a_0 \in Z_0(G)} \Bigl\{ Z_0 = a_0, \cdots ,Z_n = a_n \Bigr\}
           \]
           しかも、右辺の$\Bigl\{ \quad \bullet \quad \Bigr\}$の集合は、
           $a_i$達が変わるたびにdisjointである。
           さて、測度の可算加法性から次のような計算ができる。
           \begin{align*}
             \int_G I_{\{Z_{n+1} = j\}} d\PP^{\mu}
             &= \PP^{\mu}(G \cap \{Z_{n+1} = j\}) \\
             &=\PP^{\mu} \Biggl( \biggl( \bigcup_{a_n \in Z_n(G)} \cdots \bigcup_{a_0 \in Z_0(G)} \Bigl\{ Z_0 = a_0, \cdots ,Z_n = a_n \Bigr\} \biggl) \, \cap \, \{Z_{n+1} = j \} \Biggr) \\
             &= \sum_{a_n \in Z_n(G)} \cdots \sum_{a_0 \in Z_0(G)} \PP^{\mu}(Z_0 = a_0, \cdots , Z_n = a_n, Z_{n+1}=j) \\
             &= \sum_{a_n \in Z_n(G)} \cdots \sum_{a_0 \in Z_0(G)}\mu_{a_0}p_{a_0 a_1}\cdots p_{a_{n-1}a_n}p_{a_{n}j}\\
             &= \sum_{a_n \in Z_n(G)} \cdots \sum_{a_0 \in Z_0(G)}\PP^{\mu}(Z_0 = a_0, \cdots ,Z_n = a_n)p_{a_{n}j}\\
             &= \sum_{a_n \in Z_n(G)}\PP^{\mu}(Z_n = a_n)p_{a_{n}j}
           \end{align*}
           一方、
           \begin{align*}
             \int_G p(X_n ,j) d\PP^{\mu}
             &= \int p(X_n ,j) I_{A} d\PP^{\mu} \\
             &=\sum_{a_n \in Z_n(G)}\PP^{\mu}(Z_n = a_n)p_{a_{n}j}
           \end{align*}
           である。ただしここで
           \[
              A := \bigcup_{a_n \in Z_n(G)}\{Z_n = a_n\}
           \]
           としている\footnote{\LaTeX の表記の都合上こうしました}。
           したがって示したい等式がしめせた。
        \end{proof}

      \subsubsection{104ページ上から3行目の式}
        これももう少し書いてあげたほうが良いのでは......。
        \[
          \EE^{\mu}[ h(Z_{n+1}) \mid \mathcal{F}_n] = \sum_{j} p(Z_n, j)h(j)
        \]
        について。
        \begin{proof}
          $E$の元に番号付けをして$e_0, e_1, \cdots$とする。
          \begin{align*}
            Z_{n+1} &= Z_{n+1}I_{\{Z_{n+1} = e_0\}} + Z_{n+1}I_{\{Z_{n+1} = e_1\}} + \cdots \\
            &= \sum_{j \in E}Z_{n+1}I_{\{Z_{n+1} = j\}}
          \end{align*}
          より、
          \[
            h(Z_{n+1}) = \sum_{j \in E}h(j)I_{\{Z_{n+1} = j\}} =: X
          \]
          とする。また、
          \[
            X_m := \sum_{k=0}^m h(e_k)I_{\{Z_{n+1}=e_k\}}
          \]
          とする。
          $h,I$はともに非負の関数だから$0 \leq X_m$であり、
          $X_m \uparrow X$であるから、(cMON)より、
          \begin{align*}
            \EE^{\mu}[X \mid \mathcal{F}_n]
            &= \lim_{m \to \infty}\EE^{\mu}[X_m \mid \mathcal{F}_n]\\
            &= \lim_{m \to \infty}\EE^{\mu}[\sum_{k=0}^m h(e_k)I_{\{Z_{n+1}=e_k\}} \mid \mathcal{F}_n]\\
            &= \lim_{m \to \infty}\sum_{k=0}^m\EE^{\mu}[ h(e_k)I_{\{Z_{n+1}=e_k\}} \mid \mathcal{F}_n]\\
            &= \lim_{m \to \infty}\sum_{k=0}^m h(e_k)\EE^{\mu}[ I_{\{Z_{n+1}=e_k\}} \mid \mathcal{F}_n]\\
            &= \sum_{j \in E}h(j)\EE^{\mu}[ I_{\{Z_{n+1}=j\}} \mid \mathcal{F}_n]\\
            &= \sum_{j \in E}h(j)\PP^{\mu}(Z_{n+1}=j \mid \mathcal{F}_n)\\
            &= \sum_{j \in E}h(j)p(Z_{n},j)\\
          \end{align*}
        \end{proof}

      \subsubsection{104ページ上から4行目}
        "$h(Z_n)$ is a non-negative supermartingale"とあるが、嘘っぽい。
        初期分布の$\mu$がディラックのデルタならおそらく問題はない。
        $h$が有限という仮定しかない。
        なので、$\EE[|h(Z_n)|]$もとい、
        supermartingaleの性質より$\EE[|h(Z_0)|]$が有限かどうか
        という判定はできなさそう。
        おそらく$h$が有界という条件ならうまくいくのでは......？
        もしかしてmartingaleの三番目の条件が成り立ったから、
        と言ってそこで安心してsupermartingaleだって言ってる......？
        僕が何かを見落としている可能性が大なので参考程度に。

      \subsubsection{104ページExercise}
        マルコフ連鎖を本格的にやっていないのにこのExercise
        をやらせるのは酷なのでは......

        等式の証明には次の事実を用いる。
        \[
          \PP^i (T_j = m+1) = \sum_{k \neq j}p_{ik}\PP^k (T_j = m)
        \]
        これはマルコフ性を用いれば証明できる。
        が、詳しい証明は確率過程に焦点を当てた教科書に載っている。
        Poel "Introduction to Stachastic processes"など参照。
        しかし、直観的にも明らか。
        $m+1$で初めて$j$に行くのは、
        $1$\, stepめではいったん$j$出ないところに進み
        その後$m$\,stepかけて$j$に向かうと思えばよい。
        次の段落から解答を書きます。

        まず、次を示す。
        \[
          \PP^i(T_j < n+1) = \sum_{k \neq j} p_{ik}\PP^k(T_j < n) + p_{ij}\quad (n \ge 1)
        \]

        [$n=1$のとき]
        \begin{align*}
          \text{(左辺)} &= \PP^i(T_j < 2) = \PP^i(T_j \leq 1) = p_{ij}\\
          \text{(右辺)} &= \sum_{k \neq j} p_{ik}\PP^k(T_j < 1) + p_{ij}\\
          &= 0 + p_{ij} \\
          &= p_{ij}
        \end{align*}
        より成立する。

        [$n=m$のとき成立すると仮定]
        \begin{align*}
          \PP^i(T_{j} < m + 1 + 1) &= \PP^i(T_J < m + 2)\\
          &= \PP^i(T_j < m + 1) + \PP^i(T_j = m + 1)\\
          &= \sum_{k \neq j} p_{ik}\PP^k(T_j < m) + p_{ij} + \sum_{k \neq j}p_{ik}\PP^k (T_j = m)\\
          &= \sum_{k \neq j} p_{ik}\PP^k(T_j \leq m) + p_{ij}\\
          &= \sum_{k \neq j} p_{ik}\PP^k(T_j < m + 1)
        \end{align*}
        よって、$m+1$についても成立する。

        今示した等式について、$n \rightarrow \infty$とする。
        \[
          \lim_{n \to \infty}\PP^i(T_j < n+1) = \lim_{n \to \infty}\sum_{k \neq j} p_{ik}\PP^k(T_j < n) + p_{ij}
        \]
        左辺は測度のMONより、
        \[
          \text{(左辺)} = \PP^i(T_j < \infty)
        \]
        右辺は(多分)DOMで極限が$\sum$の中に入って、
        そのあと測度のMONより、
        \[
          \text{(右辺)} = \sum_{k \neq j} p_{ik}\PP^k(T_j < \infty) + p_{ij}
        \]
        以上により、
        \[
          f_{ij} = \sum_{k \neq j} p_{ik}f_{kj} + p_{ij}
        \]
        がわかる。

        残りは次を証明することである。
        \begin{center}
          遷移行列の各成分が$0$より大きいマルコフ連鎖$Z$がある
          \footnote{「遷移行列の各成分が$0$より大きい」
          という条件は教科書にはなかったですが、僕の証明では
          この仮定がないと証明にならないのです......。
          でも、この証明が一番自然なんだよなあと思うんだけど}。
          このとき、全ての$P$-superharmonic関数が定数関数なら、
          マルコフ連鎖$Z$は既約で再帰的である。
        \end{center}

        まず、
        \[
          f_j(i) = \PP^i(T_j < \infty)
        \]
        とおく。
        作用素$P$の定義通りに計算すると、
        $f_j$が$P$-superharmonic関数であることが分かる。
        仮定より$f_j$は定数関数となるので、それを$\alpha$とおくことにする。
        \begin{align*}
          f_j(i) &= f_{ij}\\
          \alpha &= \sum_{k \neq j} p_{ik}f_{kj} + p_{ij}\\
          \alpha &= \sum_{k \neq j} p_{ik}f_j(k) + p_{ij}\\
          \alpha &= \alpha\sum_{k \neq j} p_{ik} + p_{ij}\\
          \alpha \left(1 - \sum_{k \neq j} p_{ik} \right) &= p_{ij}\\
          \alpha &= \frac{p_{ij}}{1 - \sum_{k \neq j} p_{ik}}\\
          \alpha &= \frac{p_{ij}}{p_{ij}}\\
          \alpha &= 1
        \end{align*}
        よって、
        \[
          \PP^i(T_j < \infty) =f_{j}(i) = \alpha = 1
        \]
        である。$i,j$は任意より、$Z$は既約で再帰的である\footnote{この証明は$p_{ij} > 0$であることを使っておるのじゃ}。
